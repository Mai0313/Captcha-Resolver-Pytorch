_target_: lightning.pytorch.trainer.Trainer

default_root_dir: ${paths.output_dir}

min_epochs: 5 # prevents early stopping
max_epochs: 10

accelerator: gpu
strategy: auto
devices: auto
num_nodes: 1

# mixed precision for extra speed-up
precision: 32-true
logger: True
callbacks: [checkpoint_callback]
fast_dev_run: False
min_steps: null
max_time: null
limit_train_batches: null
limit_val_batches: null
limit_test_batches: null
limit_predict_batches: null
overfit_batches: 0.0
val_check_interval: null
num_sanity_val_steps: null
log_every_n_steps: null
enable_checkpointing: null
enable_progress_bar: True
enable_model_summary: null
accumulate_grad_batches: 1
gradient_clip_val: null
gradient_clip_algorithm: null
benchmark: null
inference_mode: True
use_distributed_sampler: True
detect_anomaly: False
barebones: False
plugins: null
sync_batchnorm: False
reload_dataloaders_every_n_epochs: 0

# perform a validation loop every N training epochs
check_val_every_n_epoch: 1

# set True to to ensure deterministic results
# makes training slower but gives more reproducibility than just setting seeds
deterministic: False
